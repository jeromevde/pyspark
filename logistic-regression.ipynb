{
  "metadata": {
    "name": "logistic-regression",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql import SparkSession\nspark \u003d SparkSession.builder.appName(\u0027logistic\u0027).getOrCreate()"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.classification import LogisticRegression"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndata \u003d spark.read.csv(\u0027s3://jerome-vanderelst-spark-data/customer_churn.csv\u0027, inferSchema\u003dTrue, header\u003dTrue)\ndata.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndata.describe().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndata.columns"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.feature import VectorAssembler\nassembler \u003d VectorAssembler(inputCols\u003d[\u0027Age\u0027, \u0027Total_Purchase\u0027, \u0027Account_Manager\u0027, \u0027Years\u0027, \u0027Num_Sites\u0027], outputCol\u003d\u0027features\u0027)\noutput \u003d assembler.transform(data)"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfinal_data\u003doutput.select(\u0027features\u0027, \u0027churn\u0027)\ntrain_churn, test_churn\u003d  final_data.randomSplit([0.7,0.3])"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.classification import LogisticRegression\nlr_churn \u003d LogisticRegression(labelCol\u003d\u0027churn\u0027)\nfitted_churn_model \u003d lr_churn.fit(train_churn)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ntraining_sum \u003d fitted_churn_model.summary\ntraining_sum.predictions.describe().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\npred_and_labels \u003d fitted_churn_model.evaluate(test_churn)\npred_and_labels.predictions.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nchurn_eval \u003d BinaryClassificationEvaluator(rawPredictionCol\u003d\u0027prediction\u0027, \n                                            labelCol\u003d\u0027churn\u0027)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nauc \u003d churn_eval.evaluate(pred_and_labels.predictions)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nauc"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nnew_customers \u003d spark.read.csv(\"s3://jerome-vanderelst-spark-data/new_customers.csv\", inferSchema\u003dTrue, header\u003dTrue)\nnew_customers.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nnew_customers.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ntest_new_customers \u003d assembler.transform(new_customers)"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ntest_new_customers.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfinal_results\u003d  fitted_churn_model.transform(test_new_customers)\nfinal_results.select(\u0027Company\u0027,\u0027prediction\u0027).show()"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ntest_new_customers.describe().show()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}